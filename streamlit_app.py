import streamlit as st
import requests
from bs4 import BeautifulSoup
from docx import Document
from io import BytesIO
import base64

@st.cache_data
def search_naver_news(keyword, num_articles):
    url = f"https://search.naver.com/search.naver?where=news&query={keyword}&sm=tab_jum&sort=0"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'lxml')

    news_list = []
    seen_titles = set()

    news_elements = soup.select("ul.list_news > li")

    for element in news_elements[:num_articles]:
        title = element.select_one("a.news_tit").get_text()
        summary = element.select_one("div.news_dsc").get_text()
        link = element.select_one("a.news_tit")['href']

        if title not in seen_titles:
            seen_titles.add(title)
            news_list.append({
                'title': title,
                'summary': summary,
                'link': link
            })

    return news_list

def create_word_document(news_list, keyword):
    doc = Document()
    doc.add_heading(f"'{keyword}' ê´€ë ¨ ë‰´ìŠ¤", 0)

    for idx, news in enumerate(news_list, 1):
        doc.add_heading(f"{idx}. {news['title']}", level=1)
        doc.add_paragraph(news['summary'])
        doc.add_paragraph(f"ë§í¬: {news['link']}")
        doc.add_paragraph("\n")

    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

def get_download_link(buffer, filename):
    b64 = base64.b64encode(buffer.getvalue()).decode()
    return f'<a href="data:application/vnd.openxmlformats-officedocument.wordprocessingml.document;base64,{b64}" download="{filename}">ë‹¤ìš´ë¡œë“œ</a>'

st.set_page_config(page_title="ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬", page_icon="ğŸ“°", layout="wide")

st.title("ğŸ“° ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬")

st.markdown("""
    <style>
    .stApp {
        max-width: 800px;
        margin: 0 auto;
    }
    .news-item {
        background-color: #f0f2f6;
        border-radius: 5px;
        padding: 10px;
        margin-bottom: 10px;
    }
    .news-title {
        font-weight: bold;
        color: #1e3a8a;
    }
    .news-summary {
        font-size: 0.9em;
        color: #374151;
    }
    .stButton > button {
        width: 100%;
    }
    </style>
""", unsafe_allow_html=True)

keyword = st.text_input("ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
num_articles = st.slider("ê°€ì ¸ì˜¬ ê¸°ì‚¬ ìˆ˜", 1, 20, 5)

col1, col2, col3 = st.columns([2, 2, 1])

if col2.button("ë‰´ìŠ¤ ê²€ìƒ‰"):
    if keyword:
        with st.spinner("ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
            news_results = search_naver_news(keyword, num_articles)
        
        if news_results:
            st.session_state.news_results = news_results
            st.success(f"'{keyword}'ì— ëŒ€í•œ ìƒìœ„ {len(news_results)}ê°œ ë‰´ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
            for idx, news in enumerate(news_results, 1):
                st.markdown(f"""
                <div class="news-item">
                    <p class="news-title">{idx}. {news['title']}</p>
                    <p class="news-summary">{news['summary']}</p>
                    <a href="{news['link']}" target="_blank">ê¸°ì‚¬ ì½ê¸°</a>
                </div>
                """, unsafe_allow_html=True)
        else:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
    else:
        st.error("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

if col3.button("ë‹¤ìš´ë¡œë“œ"):
    if 'news_results' in st.session_state and st.session_state.news_results:
        word_buffer = create_word_document(st.session_state.news_results, keyword)
        st.markdown(get_download_link(word_buffer, f"{keyword}_news.docx"), unsafe_allow_html=True)
    else:
        st.warning("ë¨¼ì € ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ì£¼ì„¸ìš”.")
